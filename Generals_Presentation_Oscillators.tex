% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 

\documentclass{beamer}

% There are many different themes available for Beamer. A comprehensive
% list with examples is given here:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
% You can uncomment the themes below if you would like to use a different
% one:
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla} %Not bad
%\usetheme{boxes}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{default}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Synchronization of Circadian Oscillators}

% A subtitle is optional and this may be deleted
\subtitle{Mean Field Game Formulation}

%\author{Christy Graves}
\author[Christy Graves]{Christy Graves\\{\small Advisor: Ren\'{e} Carmona}}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Princeton University] % (optional, but mostly needed)
{
	Program in Applied and Computational Mathematics\\
	Princeton University
}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date{Generals, May 4 2017}
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

%\subject{Theoretical Computer Science}
% This is only inserted into the PDF information catalog. Can be left
% out. 

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}

% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

% Let's get started
\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Outline}
  \tableofcontents
  % You might wish to add the option [pausesections]
\end{frame}

% Section and subsections will appear in the presentation overview
% and table of contents.
\section{Introduction}
%\frame{\tableofcontents[currentsection]}

\begin{frame}{Circadian Oscillators}
	\begin{itemize}
		\item {
			Cells in Suprachiasmatic Nucleus (SCN) responsible for circadian rhythm.
		}
		\item Order of $10^4$ neuronal cells.
		\item Each cell exhibits oscillatory dynamics.
		\item Each cell has a preferred frequency $\omega$ that varies from cell to cell.
		\item $\mathbb{E}(\omega)=\frac{2\pi}{24.5}$
		\item Cells want to synchronize with each other, as well any external sources (e.g. the sun).
	\end{itemize}
\end{frame}


\begin{frame}{Brief Intro to MFG}{N player stochastic game}
		$N$ players each make a decision (or control) $\alpha_t^i \in \mathbb{A}$ at time $t$ in an attempt to minimize their cost functions, $J^i$. For example:
		\begin{equation}
		\begin{split}
		J^i(\alpha^i,X^{1,\alpha},...X^{N,\alpha})=&\mathbb{E}\Bigg[\int_{0}^{T}f^i(t,\alpha_t^i,X_t^{1,\alpha},...X_t^{N,\alpha})dt \\
		&+g^i(X_T^{1,\alpha},...X_T^{N,\alpha}) \Bigg]
		\end{split}
		\end{equation}
		where $X_t^{i,\alpha}$ is the state of player $i$ at time $t$, given by:
		\begin{equation}
		dX_t^i=b(t,\alpha_t^i,X_t^{i,\alpha},\bar{\mu}_t)dt+\sigma(t,\alpha_t^i,X_t^{i,\alpha},\bar{\mu}_t)dW_t
		\end{equation}
		and $f^i$ and $g^i$ are the running costs and terminal costs, respectively.
\end{frame}

	\begin{frame}{Brief Intro to MFG}{Moving to Mean Field}
		\begin{itemize}
			\item {
				Assume players are symmetric.
			}
			\item {
				Consider the limit $N \rightarrow \infty$ and consider the mean field game.
		    }
			\item {
				Generic player has control $\alpha_t \in \mathbb{A}$ and state $X_t^{\alpha}$.
			}
			\item {
				Distribution of players' states over time: $\mu=(\mu_t)_{0 \leq t \leq T}$.
			}
			\item {
				Cost for generic player:
				\begin{equation}
				J(\alpha,X^{\alpha},\mu)=\mathbb{E}\Bigg[\int_{0}^{T}f(t,\alpha_t,X_t^{\alpha},\mu_t)dt+g(X_T^{\alpha},\mu_T) \Bigg]
				\end{equation}
			}
			\pause
			\item {
				Goal: find analog to Nash equilibrium
			}
		\end{itemize}
	\end{frame}

\section{State of the Art}

\subsection{Mean Field Games}

\begin{frame}{State of the Art: Mean Field Games}{Analytic Approach}
	Strategy:
	\begin{itemize}
				\item {
					Fix flow of measures: $\mu=(\mu_t)_{0 \leq t \leq T}$
				}
				\item {
					Solve stochastic control problem: find $\alpha^{\mu} \in \argmin J(\alpha,X^{\alpha},\mu)$
				}
				\item {
					Find fixed point: $\mu$ s.t. $\mathcal{L}(X_t^{\alpha^{\mu}})=\mu_t$
				}
	\end{itemize}
\end{frame}
		
\begin{frame}{State of the Art: Mean Field Games}{Analytic Approach: Stochastic Control Problem}
	\begin{itemize}
				\item {
					Define the value function:
					\begin{equation}
					\begin{split}
					V(t,x)=\inf_{\alpha \in \mathbb{A}}\mathbb{E}&\Bigg[\int_{t}^{T}f(s,\alpha_s,X_s^{\alpha},\mu_s)ds \\
					&+g(X_T^{\alpha},\mu_T) \mid X_t = x \Bigg]
					\end{split}
					\end{equation}
				}
			\end{itemize}
\end{frame}
		
\begin{frame}{State of the Art: Mean Field Games}{Analytic Approach: Stochastic Control Problem: HJB Equation}
	\begin{itemize}
				\item {
					The value function satisfies the HJB equation:
					\begin{block}{Hamilton Jacobi Bellman Equation}
						\begin{equation}
						\begin{split}
						\partial_tV(t,x)+ H(t,x, \mu_t,\partial_x V,\hat{\alpha}(t,x,\mu_t, \partial_x V))&=0 \\
						V(T,x)&=g(x,\mu_T)
						\end{split}
						\end{equation}
					\end{block}
					where  $H$ is the Hamiltonian, and $\hat{\alpha}$ is chosen to minimize the Hamiltonian.
				}
				\item {
					Derivation from the dynamic programming principle and It\^{o}'s formula
				}
			\end{itemize}
\end{frame}
		
\begin{frame}{State of the Art: Mean Field Games}{Analytic Approach: Kolmogorov (or Fokker-Planck) Equation}
	\begin{itemize}
				\item {
					Solving HJB gives us an optimal control: $\alpha(t,x)$.
				}
				\item {
					If all players use the optimal control, what is $\mathcal{L}(X_t^{\alpha})=:\mu_t$?
				}
				\item {
					This is given by the Kolmogorov (or Fokker-Planck) equation:
					\begin{block}{Kolmogorov Equation}
						\begin{equation}
						\begin{split}
						\partial_t \mu_t-\frac{1}{2} trace(\sigma \sigma^T \partial_{xx}^2 \mu_t)& \\
						+ div(b(t,x, \mu_t,\hat{\alpha}(t,x,\mu_t, \partial_x V))\cdot \mu_t)&=0 \\
						\mu_0&= \mu^0   
						\end{split}
						\end{equation}
					\end{block}
				}
				\item {
					Derivation from It\^{o}'s formula and integration by parts
				}
			\end{itemize}
\end{frame}
		
\begin{frame}{State of the Art: Mean Field Games}{Analytic Approach: Strategy Summary}
	\begin{itemize}
				\item {
					Goal: find $V, \mu$ solving HJB and Kolmogorov.
				}
				\item {
					Step 0: start with some guess for $\mu=(\mu_t)_{0 \leq t \leq T}$
				}
				\item {
					Step 1: Given $\mu$ and $V(T,x)$, solve HJB for $V$, which gives us optimal $\alpha$.
				}
				\item {
					Step 2: Given $\alpha$ and $\mu^0$, solve Kolmogorov for $\mu '$.
				}
				\item {
					Repeat Steps 1 and 2 until $\mu = \mu '$.
				}
				\pause
				\item {
					Note: existence, uniqueness, or convergence are not guaranteed. In general, need convexity of $\mathbb{A}$, $f$, and $g$.
				}
				\pause
				\item {
					Another note: this system of PDEs is highly coupled, nonlinear, with one PDE in the forward direction and the other in the backward direction.
				}
	\end{itemize}
\end{frame}

\begin{frame}{State of the Art: Mean Field Games}{Existence \& Uniqueness}
	\begin{itemize}
		\item {
			Cauchy-Lipschitz theory only holds for small T.
		}
		\item {
			Existence
			\begin{itemize}
				\item In general, need Lipschitz coefficients and cost functions, non-degenerate diffusion coefficient.
				\item Relies on Schauder's Fixed Point Theorem.
			\end{itemize}
		}
		\item {
			Uniqueness
			\begin{itemize}
				\item Assumming no common noise, in general, need monotone cost functions.
				\begin{itemize}
				\item Lasry Lions Monotonicity
				\item $L$-Monotonicity
				\end{itemize}
			\end{itemize}
		}
	\end{itemize}
\end{frame}

\begin{frame}{State of the Art: Mean Field Games}{Some Results}
	\begin{itemize}
		\item {
			Linear-Quadratic Games.
		}
		\begin{itemize}
			\item Stochastic maximum approach leads to matrix Ricatti equation.
		\end{itemize}
		\item Some results when cost is local.
		\begin{itemize}
			\item Cost is local and linear: Swiecicki et. al. \textit{An [imaginary time] Schr{\"o}dinger approach to mean field games.}
		\end{itemize}
		\item With common noise: Cardaliaguet et. al. \textit{The master equation and the convergence problem in mean field games.}
		\item Nonlocal cost of particular form: Graber \& Bensoussan \textit{Existence and Uniqueness of Solutions for Betrand and Cournot mean field games.}
	\end{itemize}
\end{frame}

\begin{frame}{State of the Art: Mean Field Games}{Open Problems}
	\begin{itemize}
		\item {
			More general existence and uniqueness results.
		}
		\item {
			Problems with non-convex cost functions.
		}
		\item {
			Problems with non-local cost functions.
		}
	\end{itemize}
\end{frame}

\subsection{Circadian Oscillators: Previous Work}

\begin{frame}{State of the Art: Circadian Oscillators}{Previous Work: Lu, et. al.}
\end{frame}

\begin{frame}{State of the Art: Circadian Oscillators}{Previous Work: Yin, et. al.}
\end{frame}

\begin{frame}{State of the Art: Circadian Oscillators}{Open Problems}
	\begin{itemize}
		\item { No one has formulated the dynamics of oscillators as a mean field game in the presence of an external source.
		}
	\end{itemize}
\end{frame}

\section{My Progress}

\subsection{Problem Formulation}

\begin{frame}{Problem Formulation}

\end{frame}

\subsection{Numerical Approach}

\begin{frame}{Numerical Approach}
		\begin{itemize}
			\item {
				To solve numerically, one common method is finite differences.
			}
			\item {
				The unknown function, $f$, will be approximated on a lattice of points:
				\begin{equation}
				f(t_i,x_j) \approx f(i \cdot \Delta t,j \cdot \Delta x)
				\end{equation}
			}
			\item {
				All derivatives are replaced by finite differences.
			}
			\item {
				For example, the heat equation:
				\begin{equation}
				\partial_t f= \partial_{xx}^2 f
				\end{equation}
			}
			\item {
				becomes:
				\begin{equation}
				\frac{f(t_{i+1},x)-f(t_i,x)}{\Delta t}=\frac{f(t_i,x_{j+1})-2f(t_i,x_j)+f(t_i,x_{j-1})}{\Delta x^2}
				\end{equation}
			}
		\end{itemize}
\end{frame}

\begin{frame}{Numerical Approach, continued}
	Following the analytic approach, our numerical approach is the following:
	\begin{itemize}
			\item {
				Goal: find grid functions $V(t_k,x_i,v_j)$ and $\mu_{t_k}(x_i,v_j)$ solving finite difference equations for HJB and Kolmogorov.
			}
			\item {
				Step 0: start with some guess for $\mu=(\mu_{t_k}(x_i,v_j))_{0 \leq t_k \leq T}$
			}
			\item {
				Step 1: Given $\mu$ and $V(T,x)$, solve finite difference HJB explicitly backwards in time for $V$, which gives us optimal $\alpha$.
			}
			\item {
				Step 2: Given $\alpha$ and $\mu^0$, solve finite difference Kolmogorov explicitly forwards in time for $\mu '$.
			}
			\item {
				Repeat Steps 1 and 2 until $\mu \approx \mu '$.
			}
	\end{itemize}
\end{frame}

\begin{frame}{Numerical Approach: Complications}
		\begin{itemize}
			\item {
				Curse of dimensionality: number of lattice points grows exponentially with the dimension of the state space.
				
			}
			\item {
				Stability: $\Delta t$ can't be too big (CFL condition).
				\begin{center}
					$\Delta x$ smaller and b (drift) larger $\implies$ need smaller $\Delta t$.
				\end{center}
			}
			\item {
				Accuracy: use upwind scheme for 1st order spatial derivatives
			}
			\item {
				What boundary conditions should be used?
			}
		\end{itemize}
\end{frame}

	\begin{frame}{Numerical Approach: Stability and Accuracy}
		\begin{itemize}
			\item CFL condition:
			\begin{equation} 
			\Delta t \leq \frac{1}{2(\frac{\sigma^2}{\Delta x^2}+\frac{|b|}{\Delta x})}
			\end{equation}
			\item Upwind scheme:
			\begin{equation}
			[Lf]=b \cdot \frac{\partial f}{\partial x} + \frac{\sigma^2}{2}\frac{\partial^2 f}{\partial x^2}
			\end{equation}
			\begin{equation}
			[Lf](i)=\sum_{j} L(i,j) f(x_j)
			\end{equation}
			Choose forward or backward differences such that:
			\begin{enumerate}
				\item $L(i,j)\geq 0$ when $i \neq j$.
				\item $L(i,i)=-\sum_{j\neq i} L(i,j)$
			\end{enumerate}
			
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Numerical Approach: Upwind Scheme}
		For example:
		\begin{equation}
		\left[b \cdot \frac{\partial f}{\partial x} \right](x_i)=b^{+} \cdot \frac{f(x_{i+1})-f(x_i)}{\Delta x}-b^{-} \cdot \frac{f(x_{i})-f(x_{i-1})}{\Delta x}
		\end{equation}
		\begin{equation}
		L(i,i+1)=b^{+} \cdot \frac{1}{\Delta x} \geq 0
		\end{equation}
		\begin{equation}
		L(i,i-1)=-b^{-} \cdot \frac{-1}{\Delta x} \geq 0
		\end{equation}
		\begin{equation}
		L(i,i)=b^{+} \cdot \frac{-1}{\Delta x}-b^{-} \cdot \frac{1}{\Delta x} = -[L(i,i+1)+L(i,i-1)]
		\end{equation}
	\end{frame}
	
	\begin{frame}{Numerical Approach: Stability of $\mu$}
		\begin{itemize}
			\item CFL + Upwind $\rightarrow$ Solution to Kolmogorov is a prob. measure, i.e.
			\begin{equation}
			\begin{split}
			\mu(t_n,x_i) & \geq 0 \\
			\sum_i \mu(t_n,x_i) &= 1
			\end{split}
			\end{equation}
			\item Proof:
			\begin{equation}
			\frac{\mu(t_{n+1},x_i)-\mu(t_{n},x_i)}{\Delta t}=\sum_{j} L(j,i) \mu(t_n,x_j)
			\end{equation}
			\begin{equation}
			\begin{split}
			\mu(t_{n+1},x_i)&=\mu(t_{n},x_i)+ \Delta t \cdot L(i,i)\mu(t_n,x_i) + \Delta t \cdot \sum_{j\neq i} L(j,i) \mu(t_n,x_j)  \\
			& \geq \mu(t_{n},x_i) (1+ \Delta t \cdot L(i,i))
			\end{split}
			\end{equation}
			$\mu(t_{n+1},x_i) \geq 0$ if $\Delta t \cdot| L(i,i)| \leq 1$ (CFL Condition)
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Numerical Approach: Stability of $\mu$ (continued)}
		\begin{equation}
		\begin{split}
		\sum_i \mu(t_{n+1},x_i)=& \sum_i \mu(t_{n},x_i)+\Delta t \cdot \sum_i \sum_{j} L(j,i) \mu(t_n,x_j) \\
		& = 1 + \Delta t \cdot \sum_j \Big(\sum_i L(j,i)\Big) \mu(t_n,x_j) \\
		& = 1
		\end{split}
		\end{equation}
	\end{frame}
	
\begin{frame}{Numerical Approach}
ToDo:

describe the 3 step process:
1) Start from $\mu$ uniform, $V(T)=0$
2) Start from $\mu$ traveling wave from 1)
3) Start from $\mu$ traveling wave from 1) and also with V(T) from 2)


ToDo:
Describe how to deal with eta and ergodic form of cost
\end{frame}

\subsection{Numerical Results}

\begin{frame}{Numerical Results}
	\begin{itemize}
		\item {
			My first point.
		}
		\item {
			My second point.
		}
	\end{itemize}
\end{frame}

\subsection{Analytical Progress}

\begin{frame}{Analytical Progress}
	\begin{itemize}
		\item {
			My first point.
		}
		\item {
			My second point.
		}
	\end{itemize}
\end{frame}


\section{Next Steps}
\begin{frame}{Next Steps: Numerics}
	\begin{itemize}
		\item {
			My first point.
		}
		\item {
			My second point.
		}
	\end{itemize}
\end{frame}

\begin{frame}{Next Steps: Analytically}
	\begin{itemize}
		\item {
			My first point.
		}
		\item {
			My second point.
		}
	\end{itemize}
\end{frame}

% Placing a * after \section means it will not show in the
% outline or table of contents.
\section*{Summary}
\begin{frame}{Summary}
	\begin{itemize}
		\item {
			My first point.
		}
		\item {
			My second point.
		}
	\end{itemize}
\end{frame}

\end{document}


